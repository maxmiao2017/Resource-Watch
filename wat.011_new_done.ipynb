{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wat.011  https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:64145/tab/2\n",
    "\n",
    "format: asc\n",
    "download 2000 phosphorus and nitrogen total load and retention data see readme.pdf for more info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for downloading data from remote server (may be ftp)\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from contextlib import closing\n",
    "import shutil\n",
    "\n",
    "# Library for uploading/downloading data to/from S3\n",
    "import boto3\n",
    "\n",
    "# Libraries for handling data\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "# from netCDF4 import Dataset\n",
    "# import pandas as pd\n",
    "# import scipy\n",
    "\n",
    "# Libraries for various helper functions\n",
    "# from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "import sys\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3 tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_upload = boto3.client(\"s3\")\n",
    "s3_download = boto3.resource(\"s3\")\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/raster/wat_011_global_riverine_N_P/\"\n",
    "\n",
    "s3_file1 = \"wat_011_global_riverine_N_Load_2000.asc\"\n",
    "s3_file2 = \"wat_011_global_riverine_P_Load_2000.asc\"\n",
    "s3_file3 = \"wat_011_global_riverine_N_Retention_2000.asc\"\n",
    "s3_file4 = \"wat_011_global_riverine_P_Retention_2000.asc\"\n",
    "\n",
    "s3_key_orig1 = s3_folder + s3_file1\n",
    "s3_key_edit1 = s3_key_orig1[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig2 = s3_folder + s3_file2\n",
    "s3_key_edit2 = s3_key_orig2[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig3 = s3_folder + s3_file3\n",
    "s3_key_edit3 = s3_key_orig3[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig4 = s3_folder + s3_file4\n",
    "s3_key_edit4 = s3_key_orig4[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_files_to_merge = [s3_key_edit1, s3_key_edit2, s3_key_edit3,s3_key_edit4]\n",
    "band_ids = [\"N_Load\",\"P_Load\",\"N_Retention\", \"P_Retention\"]\n",
    "s3_key_merge = s3_folder + \"Wat_011_global_riverine_Merge_2000.tif\"\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\"\\r%s  %s / %s  (%.2f%%)\"%(\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define local file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = \"/Users/Max81007/Desktop/Python/Resource_Watch/Raster/wat.011/\"\n",
    "\n",
    "file_name1 = \"Nload_2000.asc\"\n",
    "file_name2 = \"Pload_2000.asc\"\n",
    "file_name3 = \"retention_N_2000.asc\"\n",
    "file_name4 = \"retention_P_2000.asc\"\n",
    "\n",
    "\n",
    "local_orig1 = local_folder + file_name1\n",
    "local_orig2 = local_folder + file_name2\n",
    "local_orig3 = local_folder + file_name3\n",
    "local_orig4 = local_folder + file_name4\n",
    "\n",
    "\n",
    "orig_extension_length = 4 #4 for each char in .tif\n",
    "\n",
    "local_edit1 = local_orig1[:-orig_extension_length] + \"_edit.tif\" \n",
    "local_edit2 = local_orig2[:-orig_extension_length] + \"_edit.tif\" \n",
    "local_edit3 = local_orig3[:-orig_extension_length] + \"_edit.tif\" \n",
    "local_edit4 = local_orig4[:-orig_extension_length] + \"_edit.tif\" \n",
    "\n",
    "merge_files = [local_edit1, local_edit2, local_edit3, local_edit4]\n",
    "tmp_merge = local_folder + \"Foo_039_Fertilizer_TotalConsumption_Merge.tif\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use rasterio to reproject and compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'AAIGrid', 'dtype': 'float32', 'nodata': -9999.0, 'width': 720, 'height': 360, 'count': 1, 'crs': None, 'transform': Affine(0.5, 0.0, -180.0,\n",
      "       0.0, -0.5, 90.0), 'tiled': False}\n",
      "{'driver': 'AAIGrid', 'dtype': 'float32', 'nodata': -9999.0, 'width': 720, 'height': 360, 'count': 1, 'crs': None, 'transform': Affine(0.5, 0.0, -180.0,\n",
      "       0.0, -0.5, 90.0), 'tiled': False}\n",
      "{'driver': 'AAIGrid', 'dtype': 'float32', 'nodata': -9999.0, 'width': 720, 'height': 360, 'count': 1, 'crs': None, 'transform': Affine(0.5, 0.0, -180.0,\n",
      "       0.0, -0.5, 90.0), 'tiled': False}\n",
      "{'driver': 'AAIGrid', 'dtype': 'float32', 'nodata': -9999.0, 'width': 720, 'height': 360, 'count': 1, 'crs': None, 'transform': Affine(0.5, 0.0, -180.0,\n",
      "       0.0, -0.5, 90.0), 'tiled': False}\n"
     ]
    }
   ],
   "source": [
    "files = [local_orig1, local_orig2, local_orig3, local_orig4]\n",
    "for file in files:\n",
    "    with rio.open(file, 'r') as src:\n",
    "        profile = src.profile\n",
    "        print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this is the core of Vizz's netcdf2tif function\n",
    "def convert_asc_to_tif(orig_name, edit_name):\n",
    "\n",
    "    with rio.open(orig_name, 'r') as src:\n",
    "        # This assumes data is readable by rasterio\n",
    "        # May need to open instead with netcdf4.Dataset, for example\n",
    "\n",
    "        data = src.read()[0]\n",
    "\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "\n",
    "        print(rows)\n",
    "        print(columns)\n",
    "\n",
    "        # Latitude bounds\n",
    "        south_lat = -90\n",
    "        north_lat = 90\n",
    "\n",
    "        # Longitude bounds\n",
    "        west_lon = -180\n",
    "        east_lon = 180\n",
    "\n",
    "        transform = rio.transform.from_bounds(west_lon, south_lat, east_lon, north_lat, columns, rows)\n",
    "\n",
    "        # Profile\n",
    "\n",
    "        no_data_val = -9999.0\n",
    "        target_projection = 'EPSG:4326'\n",
    "        target_data_type = np.float64\n",
    "\n",
    "        profile = {\n",
    "            'driver':'GTiff', \n",
    "            'height':rows, \n",
    "            'width':columns, \n",
    "            'count':1, \n",
    "            'dtype':target_data_type, \n",
    "            'crs':target_projection, \n",
    "            'transform':transform, \n",
    "            'compress':'lzw', \n",
    "            'nodata': no_data_val\n",
    "        }\n",
    "\n",
    "        with rio.open(edit_name, \"w\", **profile) as dst:\n",
    "            dst.write(data.astype(profile[\"dtype\"]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "720\n",
      "360\n",
      "720\n",
      "360\n",
      "720\n",
      "360\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "convert_asc_to_tif(local_orig1, local_edit1)\n",
    "convert_asc_to_tif(local_orig2, local_edit2)\n",
    "convert_asc_to_tif(local_orig3, local_edit3)\n",
    "convert_asc_to_tif(local_orig4, local_edit4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "with rio.open(merge_files[0]) as src:\n",
    "    kwargs = src.profile\n",
    "    \n",
    "kwargs.update(\n",
    "    count=len(merge_files)\n",
    ")\n",
    "    \n",
    "with rio.open(tmp_merge, 'w', **kwargs) as dst:\n",
    "    for idx, file in enumerate(merge_files):\n",
    "        print(idx)\n",
    "        with rio.open(file) as src:\n",
    "\n",
    "            band = idx+1\n",
    "            windows = src.block_windows()\n",
    "\n",
    "            for win_id, window in windows:\n",
    "                src_data = src.read(1, window=window)\n",
    "                dst.write_band(band, src_data, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float64', 'nodata': -9999.0, 'width': 720, 'height': 360, 'count': 4, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.5, 0.0, -180.0,\n",
      "       0.0, -0.5, 90.0), 'compress': 'lzw', 'interleave': 'band', 'tiled': False}\n"
     ]
    }
   ],
   "source": [
    "files = [tmp_merge]\n",
    "for file in files:\n",
    "    with rio.open(file, 'r') as src:\n",
    "        profile = src.profile\n",
    "        print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload orig and edit files to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Max81007/Desktop/Python/Resource_Watch/Raster/wat.011/Foo_039_Fertilizer_TotalConsumption_Merge.tif  1717086 / 1717086.0  (100.00%)"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "s3_upload.upload_file(local_orig1, s3_bucket, s3_key_orig1,\n",
    "                         Callback=ProgressPercentage(local_orig1))\n",
    "s3_upload.upload_file(local_orig2, s3_bucket, s3_key_orig2,\n",
    "                         Callback=ProgressPercentage(local_orig2))\n",
    "s3_upload.upload_file(local_orig3, s3_bucket, s3_key_orig3,\n",
    "                         Callback=ProgressPercentage(local_orig3))\n",
    "s3_upload.upload_file(local_orig4, s3_bucket, s3_key_orig4,\n",
    "                         Callback=ProgressPercentage(local_orig4))\n",
    "\n",
    "\n",
    "# Edit\n",
    "s3_upload.upload_file(local_edit1, s3_bucket, s3_key_edit1,\n",
    "                         Callback=ProgressPercentage(local_edit1))\n",
    "s3_upload.upload_file(local_edit2, s3_bucket, s3_key_edit2,\n",
    "                         Callback=ProgressPercentage(local_edit2))\n",
    "s3_upload.upload_file(local_edit3, s3_bucket, s3_key_edit3,\n",
    "                         Callback=ProgressPercentage(local_edit3))\n",
    "s3_upload.upload_file(local_edit4, s3_bucket, s3_key_edit4,\n",
    "                         Callback=ProgressPercentage(local_edit4))\n",
    "\n",
    "s3_upload.upload_file(tmp_merge, s3_bucket, s3_key_merge,\n",
    "           Callback=ProgressPercentage(tmp_merge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wri-public-data/resourcewatch/raster/wat_011_global_riverine_N_P/Wat_011_global_riverine_Merge_2000.tif\n",
      "2017-09-28 10:13:32    1717086 Wat_011_global_riverine_Merge_2000.tif\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"Zs3_key\"] = \"s3://wri-public-data/\" + s3_key_merge\n",
    "os.environ[\"Zs3_key_inspect\"] = \"wri-public-data/\" + s3_key_merge\n",
    "os.environ[\"Zgs_key\"] = \"gs://resource-watch-public/\" + s3_key_merge\n",
    "\n",
    "!echo %Zs3_key_inspect%\n",
    "!aws s3 ls %Zs3_key_inspect%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying s3://wri-public-data/resourcewatch/raster/wat_011_global_riverine_N_P/Wat_011_global_riverine_Merge_2000.tif [Content-Type=binary/octet-stream]...\n",
      "/ [0 files][    0.0 B/  1.6 MiB]                                                \n",
      "/ [1 files][  1.6 MiB/  1.6 MiB]                                                \n",
      "-\n",
      "\n",
      "Operation completed over 1 objects/1.6 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp %Zs3_key% %Zgs_key%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started upload task with ID: SWXUHWM45AWV7QV4FB4M2POY\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"asset_id\"] = \"users/resourcewatch/wat_011_global_riverine_N_P_2000\"\n",
    "!earthengine upload image --asset_id=%asset_id% %Zgs_key%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"band_names\"] = str(band_ids)\n",
    "!earthengine asset set -p band_names=\"%band_names%\" %asset_id%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
