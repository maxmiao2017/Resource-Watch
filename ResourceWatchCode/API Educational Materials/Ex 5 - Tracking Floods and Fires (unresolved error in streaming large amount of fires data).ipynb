{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data fetching library\n",
    "import requests as req\n",
    "# used below: 'res' stands for 'response'\n",
    "\n",
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "# Data visualization libraries\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find information about all data on the Resource Watch API, format as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Base URL for getting dataset metadata from RW API\n",
    "# Metadata = Data that describes Data \n",
    "url = \"https://api.resourcewatch.org/v1/dataset?sort=slug,-provider,userId&status=saved&includes=metadata,vocabulary,widget,layer\"\n",
    "\n",
    "# page[size] tells the API the maximum number of results to send back\n",
    "# There are currently between 200 and 300 datasets on the RW API\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000}\n",
    "\n",
    "# Request all datasets, and extract the data from the response\n",
    "res = req.get(url, params=payload)\n",
    "data = res.json()[\"data\"]\n",
    "\n",
    "#############################################################\n",
    "\n",
    "### Convert the json object returned by the API into a pandas DataFrame\n",
    "# Another option: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html\n",
    "datasets_on_api = {}\n",
    "for ix, dset in enumerate(data):\n",
    "    atts = dset[\"attributes\"]\n",
    "    metadata = atts[\"metadata\"]\n",
    "    layers = atts[\"layer\"]\n",
    "    widgets = atts[\"widget\"]\n",
    "    tags = atts[\"vocabulary\"]\n",
    "    datasets_on_api[atts[\"name\"]] = {\n",
    "        \"rw_id\":dset[\"id\"],\n",
    "        \"table_name\":atts[\"tableName\"],\n",
    "        \"provider\":atts[\"provider\"],\n",
    "        \"date_updated\":atts[\"updatedAt\"],\n",
    "        \"num_metadata\":len(metadata),\n",
    "        \"metadata\": metadata,\n",
    "        \"num_layers\":len(layers),\n",
    "        \"layers\": layers,\n",
    "        \"num_widgets\":len(widgets),\n",
    "        \"widgets\": widgets,\n",
    "        \"num_tags\":len(tags),\n",
    "        \"tags\":tags\n",
    "    }\n",
    "\n",
    "# Create the DataFrame, name the index, and sort by date_updated\n",
    "# More recently updated datasets at the top\n",
    "current_datasets_on_api = pd.DataFrame.from_dict(datasets_on_api, orient='index')\n",
    "current_datasets_on_api.index.rename(\"Dataset\", inplace=True)\n",
    "current_datasets_on_api.sort_values(by=[\"date_updated\"], inplace=True, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple search:\n",
    "search_terms = [\"flood\", \"fire\"]\n",
    "# View datasets on the Resource Watch API\n",
    "dataset_matches = [name for name in current_datasets_on_api.index if any(term in name.lower() for term in search_terms)]\n",
    "\n",
    "dataset_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disaster_data = current_datasets_on_api.loc[dataset_matches]\n",
    "disaster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disaster_data.loc[\"Floods News Reports\", \"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rw_id = \"a972a30d-f766-4d68-a85d-392538b4ccf9\"\n",
    "table_name = \"flood_observatory\"\n",
    "#sql = \"SELECT st_x(the_geom) as lon, st_y(the_geom) as lat FROM flood_observatory where to_date(date_began, 'DD-Mon-YY') > (CURRENT_DATE - interval '3 year')\"\n",
    "sql_explore = \"Select * from flood_observatory\"\n",
    "\n",
    "query_base = \"https://api.resourcewatch.org/v1/query/{}?sql={}\"\n",
    "\n",
    "query = query_base.format(rw_id, sql_explore)\n",
    "#query = query_base.format(rw_id, sql)\n",
    "\n",
    "res = req.get(query)\n",
    "\n",
    "flood_data = res.json()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(flood_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map(location=[0, 0], zoom_start=1, tiles='OpenStreetMap')\n",
    "for point in flood_data:\n",
    "    folium.Marker(location=[point[\"lat\"], point[\"lon\"]]).add_to(m)\n",
    "\n",
    "m\n",
    "\n",
    "## The embedded map does not show in GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disaster_data.loc[\"VIIRS Active Fire -- Global\", \"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as req\n",
    "\n",
    "rw_id = \"20cc5eca-8c63-4c41-8e8e-134dcf1e6d76\"\n",
    "# table_name = \"vnp14imgtdl_nrt_global_7d\"\n",
    "\n",
    "sql_with_date = \"SELECT st_x(the_geom) as lon, st_y(the_geom) as lat FROM vnp14imgtdl_nrt_global_7d where to_date(substring(cast(acq_date as text), 1, 10), 'yyyy-mm-dd') > (CURRENT_DATE - interval '1 day')\"\n",
    "\n",
    "sql_with_date_count = \"SELECT count(*) FROM vnp14imgtdl_nrt_global_7d where to_date(substring(cast(acq_date as text), 1, 10), 'yyyy-mm-dd') > (CURRENT_DATE - interval '1 day')\"\n",
    "\n",
    "sql_with_date = \"SELECT acq_date FROM vnp14imgtdl_nrt_global_7d where to_date(substring(cast(acq_date as text), 1, 10), 'yyyy-mm-dd') > (CURRENT_DATE - interval '1 day')\"\n",
    "query1 = query_base.format(rw_id, sql_with_date)\n",
    "query_base = \"https://api.resourcewatch.org/v1/query/{}?sql={}\"\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 1000000000}\n",
    "#res1 = req.get(query1, params=payload)\n",
    "\n",
    "sql = \"SELECT st_x(the_geom) as lon, st_y(the_geom) as lat, acq_date as date FROM vnp14imgtdl_nrt_global_7d LIMIT {}\"\n",
    "limit = 9000\n",
    "sql = sql.format(limit)\n",
    "\n",
    "rw_id = \"20cc5eca-8c63-4c41-8e8e-134dcf1e6d76\"\n",
    "query_base = \"https://api.resourcewatch.org/v1/query/{}?sql={}\"\n",
    "query2 = query_base.format(rw_id, sql)\n",
    "\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 10000000}\n",
    "res2 = req.get(query2, params=payload)\n",
    "\n",
    "# Breaks\n",
    "#res1 = req.get(query1, params=payload)\n",
    "# Works\n",
    "\n",
    "\n",
    "    \n",
    "fire_data = res2.json()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT st_x(the_geom) as lon, st_y(the_geom) as lat, acq_date as date FROM vnp14imgtdl_nrt_global_7d LIMIT {}\"\n",
    "limit = 9000\n",
    "sql = sql.format(limit)\n",
    "\n",
    "rw_id = \"20cc5eca-8c63-4c41-8e8e-134dcf1e6d76\"\n",
    "query_base = \"https://api.resourcewatch.org/v1/query/{}?sql={}\"\n",
    "query2 = query_base.format(rw_id, sql)\n",
    "\n",
    "payload = { \"application\":\"rw\", \"page[size]\": 10000000}\n",
    "res2 = req.get(query2, params=payload)\n",
    "\n",
    "fire_data = res2.json()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fire_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fire_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rw_id = \"a9e33aad-eece-4453-8279-31c4b4e0583f\"\n",
    "#table_name = \"modis_c6_global_7d\"\n",
    "\n",
    "sql = \"SELECT st_x(the_geom) as lon, st_y(the_geom) as lat, acq_date as date FROM modis_c6_global_7d LIMIT 9500\"\n",
    "query_base = \"https://api.resourcewatch.org/v1/query/{}?sql={}\"\n",
    "query2 = query_base.format(rw_id, sql)\n",
    "res2 = req.get(query2)\n",
    "    \n",
    "fire_data = res2.json()[\"data\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fire_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### This approach didn't work for me, so I switched to below\n",
    "# #http://bobrochel.blogspot.in/2010/11/bad-servers-chunked-encoding-and.html?showComment=1358777800048\n",
    "# try:\n",
    "#     res = req.get(query)\n",
    "# except (httplib.IncompleteRead, e):\n",
    "#     res = e.partial\n",
    "    \n",
    "    \n",
    "# https://stackoverflow.com/questions/39116123/protocolerror-incompleteread-using-requests\n",
    "partial = \"\"\n",
    "\n",
    "response = req.get(query2, stream=True)\n",
    "\n",
    "if response.ok:\n",
    "    for block in response.iter_content(1024):\n",
    "        print(\"ok\")\n",
    "        print(str(block))\n",
    "        if not block:\n",
    "            break\n",
    "        partial += str(block)\n",
    "        \n",
    "### You have to adjust the end_index so that \n",
    "# the last character in partial is a }\n",
    "end_index = -3\n",
    "partial[2:end_index]\n",
    "\n",
    "import json\n",
    "fire_data = json.loads((partial[2:-3]+\"]}\").replace(\"\\'b\\'\", \"\"))[\"data\"]\n",
    "len(fire_data)\n",
    "\n",
    "## I've run this multiple times and get 389 each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fire_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fire_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map(location=[0, 0], zoom_start=1, tiles='OpenStreetMap')\n",
    "for point in fire_data:\n",
    "    folium.Marker(location=[point[\"lat\"], point[\"lon\"]]).add_to(m)\n",
    "\n",
    "m\n",
    "\n",
    "## The embedded map does not show in GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
