{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative Thermal Stress on Coral Reefs\tbio.029\thttps://coralreefwatch.noaa.gov/satellite/bleaching5km/index.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "import boto3\n",
    "import requests as req\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish s3 location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resoucewatch/<tif_folder_name>\"\n",
    "s3_file = \"<tif_file_name[s]>.tif\"\n",
    "\n",
    "s3_key_orig = s3_folder + s3_file\n",
    "s3_key_edit = s3_key_orig[0:-4] + \"_edit.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create local staging folder for holding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir staging\n",
    "os.chdir(\"staging\")\n",
    "staging_folder = os.getcwd()\n",
    "os.environ[\"Z_STAGING_FOLDER\"] = staging_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data already on s3, create a staging key and download to staging folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "staging_file = \"/<staging_tif_name>.tif\"\n",
    "staging_key_orig = staging_folder + staging_file\n",
    "staging_key_edit = staging_key_orig[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.meta.client.download_file(s3_bucket, s3_key_orig, staging_key_orig)\n",
    "s3.meta.client.download_file(s3_bucket, s3_key_edit, staging_key_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data in local storage, move to staging folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_folder = \"/Users/nathansuberi/Desktop/WRI_Programming/RW_Data\"\n",
    "rw_data_type = \"/<data_topic>\"\n",
    "# Topics include: [Society, Food, Forests, Water, Energy, Climate, Cities, Biodiversity, Commerce, Disasters]\n",
    "local_file = \"/<file_name>.tif\"\n",
    "local_key = local_folder + rw_data_type + local_file\n",
    "\n",
    "staging_key_orig = staging_folder + local_file\n",
    "staging_key_edit = staging_key_orig[0:-4] + \"_edit.tif\"\n",
    "\n",
    "os.rename(local_key, staging_key_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Regardless of any needed edits, upload original file</b>\n",
    "\n",
    "<i>Upload tif to S3 folder</i>\n",
    "\n",
    "http://boto3.readthedocs.io/en/latest/guide/s3-example-creating-buckets.html\n",
    "\n",
    "<i>Monitor Progress of Upload</i>\n",
    "\n",
    "http://boto3.readthedocs.io/en/latest/_modules/boto3/s3/transfer.html\n",
    "https://boto3.readthedocs.io/en/latest/guide/s3.html#using-the-transfer-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\n",
    "                    \"\\r%s  %s / %s  (%.2f%%)\" % (\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defined above:\n",
    "# s3_bucket\n",
    "# s3_key_orig\n",
    "# s3_key_edit\n",
    "# staging_key_orig\n",
    "# staging_key_edit\n",
    "\n",
    "s3.upload_file(staging_key_orig, s3_bucket, s3_key_orig,\n",
    "                         Callback=ProgressPercentage(staging_key_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for compression, projection\n",
    "\n",
    "Create edit file if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check Compression, Projection\n",
    "os.environ[\"Z_FILE_LOC\"] = staging_key_orig\n",
    "\n",
    "# Use GDAL command line tools... \n",
    "# can replace with rasterio eventually\n",
    "!gdalinfo $Z_FILE_LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Project & Compress\n",
    "\n",
    "# Project with gdalwarp, compress with gdal_translate\n",
    "# https://gis.stackexchange.com/questions/89444/file-size-inflation-normal-with-gdalwarp\n",
    "# http://www.gdal.org/gdalwarp.html\n",
    "# http://www.perrygeo.com/lazy-raster-processing-with-gdal-vrts.html\n",
    "\n",
    "staging_temp_file = staging_folder + \"/temp.vrt\"\n",
    "os.environ[\"Z_FILE_TEMP\"] = staging_temp_file\n",
    "!gdalwarp -t_srs EPSG:4326 -of vrt $ZFILELOC $Z_FILE_TEMP\n",
    "\n",
    "# Compress\n",
    "# http://www.gdal.org/gdal_translate.html\n",
    "\n",
    "os.environ[\"Z_FILE_DEST\"] = staging_key_edit\n",
    "!gdal_translate -of GTiff -co COMPRESS=LZW $Z_FILE_TEMP $Z_FILE_DEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gdalinfo $Z_FILE_DEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with rasterio.open(staging_key_orig) as src:\n",
    "with rasterio.open(staging_key_edit) as src:\n",
    "    profile = src.profile\n",
    "    print(profile)\n",
    "    data = src.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This works if all the raster values are positive whole numbers\n",
    "counts = {}\n",
    "for row in range(data[:,0].shape[0]):\n",
    "    cts = np.bincount(data[row,:])\n",
    "    for val, ct in enumerate(cts):\n",
    "        try:\n",
    "            counts[val] += ct\n",
    "        except:\n",
    "            counts[val] = ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload edited files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defined above:\n",
    "# s3_bucket\n",
    "# s3_key_orig\n",
    "# s3_key_edit\n",
    "# staging_key_orig\n",
    "# staging_key_edit\n",
    "\n",
    "s3.upload_file(staging_key_edit, s3_bucket, s3_key_edit,\n",
    "                         Callback=ProgressPercentage(staging_key_edit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer definition\n",
    "\n",
    "https://github.com/resource-watch/notebooks/blob/master/ResourceWatch/Api_definition/layer_definition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to server destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Too big for ArcGIS Online to upload using their web interface... 1 GB limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove data from computer / instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "!rm -r $Z_STAGING_FOLDER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
