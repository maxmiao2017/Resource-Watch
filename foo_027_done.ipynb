{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foo.027\t- Observed and Potential Crop Yields\n",
    "\n",
    "Description: http://www.earthstat.org/data-download/\n",
    "Download as Yield Gaps and Climate Bins for Major Crops - Geotiff format :http://www.earthstat.org/data-download/\n",
    "\n",
    "File type: Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for downloading data from remote server (may be ftp)\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from contextlib import closing\n",
    "import shutil\n",
    "\n",
    "# Library for uploading/downloading data to/from S3\n",
    "import boto3\n",
    "\n",
    "# Libraries for handling data\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "# from netCDF4 import Dataset\n",
    "# import pandas as pd\n",
    "# import scipy\n",
    "\n",
    "# Libraries for various helper functions\n",
    "# from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "import sys\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define local file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = \"/Users/Max81007/Desktop/Python/Resource_Watch/Raster/foo.027/yieldgap_geotiff/\"\n",
    "\n",
    "sub_folder1 = \"barley_yieldgap_geotiff/\"\n",
    "sub_folder2 = \"maize_yieldgap_geotiff/\"\n",
    "sub_folder3 = \"rice_yieldgap_geotiff/\"\n",
    "sub_folder4 = \"soybean_yieldgap_geotiff/\"\n",
    "\n",
    "file_name1 = \"barley_yieldgap\"\n",
    "file_name2 = \"barley_yieldpotential\"\n",
    "file_name3 = \"maize_yieldgap\"\n",
    "file_name4 = \"maize_yieldpotential\"\n",
    "file_name5 = \"rice_yieldgap\"\n",
    "file_name6 = \"rice_yieldpotential\"\n",
    "file_name7 = \"soybean_yieldgap\"\n",
    "file_name8 = \"soybean_yieldpotential\"\n",
    "\n",
    "local_orig1 = local_folder+ sub_folder1 + file_name1 + \".tif\" \n",
    "local_orig2 = local_folder+ sub_folder1 + file_name2 + \".tif\" \n",
    "local_orig3 = local_folder+ sub_folder2 + file_name3 + \".tif\" \n",
    "local_orig4 = local_folder+ sub_folder2 + file_name4 + \".tif\" \n",
    "local_orig5 = local_folder+ sub_folder3 + file_name5 + \".tif\" \n",
    "local_orig6 = local_folder+ sub_folder3 + file_name6 + \".tif\" \n",
    "local_orig7 = local_folder+ sub_folder4 + file_name7 + \".tif\" \n",
    "local_orig8 = local_folder+ sub_folder4 + file_name8 + \".tif\" \n",
    "\n",
    "orig_extension_length = 4 #4 for each char in .tif\n",
    "\n",
    "local_edit1 = local_orig1[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit2 = local_orig2[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit3 = local_orig3[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit4 = local_orig4[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit5 = local_orig5[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit6 = local_orig6[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit7 = local_orig7[:-orig_extension_length] + \"edit.tif\" \n",
    "local_edit8 = local_orig8[:-orig_extension_length] + \"edit.tif\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_upload = boto3.client(\"s3\")\n",
    "s3_download = boto3.resource(\"s3\")\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/raster/foo_027_yield_gaps_for_major_crops/\"\n",
    "\n",
    "s3_key_orig1 = s3_folder + file_name1 + \".tif\" \n",
    "s3_key_edit1 = s3_key_orig1[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig2 = s3_folder + file_name2 + \".tif\" \n",
    "s3_key_edit2 = s3_key_orig2[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig3 = s3_folder + file_name3 + \".tif\" \n",
    "s3_key_edit3 = s3_key_orig3[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig4 = s3_folder + file_name4 + \".tif\" \n",
    "s3_key_edit4 = s3_key_orig4[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig5 = s3_folder + file_name5 + \".tif\" \n",
    "s3_key_edit5 = s3_key_orig5[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig6= s3_folder + file_name6 + \".tif\" \n",
    "s3_key_edit6 = s3_key_orig6[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig7 = s3_folder + file_name7 + \".tif\" \n",
    "s3_key_edit7 = s3_key_orig7[0:-4] + \"_edit.tif\"\n",
    "\n",
    "s3_key_orig8 = s3_folder + file_name8 + \".tif\" \n",
    "s3_key_edit8 = s3_key_orig8[0:-4] + \"_edit.tif\"\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\"\\r%s  %s / %s  (%.2f%%)\"%(\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_ids = [file_name1, file_name2, file_name3, file_name4, file_name5, file_name6, file_name7, file_name8]\n",
    "merge_name = \"foo_027_yield_gaps_for_major_crops.tif\"\n",
    "s3_key_merge = s3_folder + merge_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_files = [local_edit1, local_edit2, local_edit3, local_edit4, local_edit5, local_edit6, local_edit7, local_edit8]\n",
    "tmp_merge = local_folder + merge_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use rasterio to reproject and compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.402823e+38, 'width': 4320, 'height': 2160, 'count': 1, 'crs': CRS({'init': 'epsg:4326'}), 'transform': Affine(0.0833333333333286, 0.0, -180.0,\n",
      "       0.0, -0.0833333333333286, 89.99999999998977), 'blockxsize': 128, 'blockysize': 128, 'tiled': True, 'interleave': 'band'}\n"
     ]
    }
   ],
   "source": [
    "files = [local_orig1, local_orig2, local_orig3, local_orig4, local_orig5, local_orig6, local_orig7, local_orig8]\n",
    "for file in files:\n",
    "    with rio.open(file, 'r') as src:\n",
    "        profile = src.profile\n",
    "        print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this is the core of Vizz's netcdf2tif function\n",
    "def convert_asc_to_tif(orig_name, edit_name):\n",
    "\n",
    "    with rio.open(orig_name, 'r') as src:\n",
    "        # This assumes data is readable by rasterio\n",
    "        # May need to open instead with netcdf4.Dataset, for example\n",
    "\n",
    "        data = src.read()[0]\n",
    "\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "\n",
    "        print(rows)\n",
    "        print(columns)\n",
    "\n",
    "        # Latitude bounds\n",
    "        south_lat = -90\n",
    "        north_lat = 90\n",
    "\n",
    "        # Longitude bounds\n",
    "        west_lon = -180\n",
    "        east_lon = 180\n",
    "\n",
    "        transform = rio.transform.from_bounds(west_lon, south_lat, east_lon, north_lat, columns, rows)\n",
    "\n",
    "        # Profile\n",
    "\n",
    "        no_data_val = -3.402823e+38\n",
    "        target_projection = 'EPSG:4326'\n",
    "        target_data_type = np.float64\n",
    "\n",
    "        profile = {\n",
    "            'driver':'GTiff', \n",
    "            'height':rows, \n",
    "            'width':columns, \n",
    "            'count':1, \n",
    "            'dtype':target_data_type, \n",
    "            'crs':target_projection, \n",
    "            'transform':transform, \n",
    "            'compress':'lzw', \n",
    "            'nodata': no_data_val\n",
    "        }\n",
    "\n",
    "        with rio.open(edit_name, \"w\", **profile) as dst:\n",
    "            dst.write(data.astype(profile[\"dtype\"]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n",
      "2160\n",
      "4320\n"
     ]
    }
   ],
   "source": [
    "convert_asc_to_tif(local_orig1, local_edit1)\n",
    "convert_asc_to_tif(local_orig2, local_edit2)\n",
    "convert_asc_to_tif(local_orig3, local_edit3)\n",
    "convert_asc_to_tif(local_orig4, local_edit4)\n",
    "convert_asc_to_tif(local_orig5, local_edit5)\n",
    "convert_asc_to_tif(local_orig6, local_edit6)\n",
    "convert_asc_to_tif(local_orig7, local_edit7)\n",
    "convert_asc_to_tif(local_orig8, local_edit8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "with rio.open(merge_files[0]) as src:\n",
    "    kwargs = src.profile\n",
    "    \n",
    "kwargs.update(\n",
    "    count=len(merge_files)\n",
    ")\n",
    "    \n",
    "with rio.open(tmp_merge, 'w', **kwargs) as dst:\n",
    "    for idx, file in enumerate(merge_files):\n",
    "        print(idx)\n",
    "        with rio.open(file) as src:\n",
    "\n",
    "            band = idx+1\n",
    "            windows = src.block_windows()\n",
    "\n",
    "            for win_id, window in windows:\n",
    "                src_data = src.read(1, window=window)\n",
    "                dst.write_band(band, src_data, window=window)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload orig and edit files to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Max81007/Desktop/Python/Resource_Watch/Raster/foo.027/yieldgap_geotiff/foo_027_yield_gaps_for_major_crops.tif  27609834 / 27609834.0  (100.00%)15.0  (100.00%)"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "s3_upload.upload_file(local_orig1, s3_bucket, s3_key_orig1,\n",
    "                         Callback=ProgressPercentage(local_orig1))\n",
    "s3_upload.upload_file(local_orig2, s3_bucket, s3_key_orig2,\n",
    "                         Callback=ProgressPercentage(local_orig2))\n",
    "s3_upload.upload_file(local_orig3, s3_bucket, s3_key_orig3,\n",
    "                         Callback=ProgressPercentage(local_orig3))\n",
    "s3_upload.upload_file(local_orig4, s3_bucket, s3_key_orig4,\n",
    "                         Callback=ProgressPercentage(local_orig4))\n",
    "s3_upload.upload_file(local_orig5, s3_bucket, s3_key_orig5,\n",
    "                         Callback=ProgressPercentage(local_orig5))\n",
    "s3_upload.upload_file(local_orig6, s3_bucket, s3_key_orig6,\n",
    "                         Callback=ProgressPercentage(local_orig6))\n",
    "s3_upload.upload_file(local_orig7, s3_bucket, s3_key_orig7,\n",
    "                         Callback=ProgressPercentage(local_orig7))\n",
    "s3_upload.upload_file(local_orig8, s3_bucket, s3_key_orig8,\n",
    "                         Callback=ProgressPercentage(local_orig8))\n",
    "\n",
    "# Edit\n",
    "s3_upload.upload_file(local_edit1, s3_bucket, s3_key_edit1,\n",
    "                         Callback=ProgressPercentage(local_edit1))\n",
    "s3_upload.upload_file(local_edit2, s3_bucket, s3_key_edit2,\n",
    "                         Callback=ProgressPercentage(local_edit2))\n",
    "s3_upload.upload_file(local_edit3, s3_bucket, s3_key_edit3,\n",
    "                         Callback=ProgressPercentage(local_edit3))\n",
    "s3_upload.upload_file(local_edit4, s3_bucket, s3_key_edit4,\n",
    "                         Callback=ProgressPercentage(local_edit4))\n",
    "s3_upload.upload_file(local_edit5, s3_bucket, s3_key_edit5,\n",
    "                         Callback=ProgressPercentage(local_edit5))\n",
    "s3_upload.upload_file(local_edit6, s3_bucket, s3_key_edit6,\n",
    "                         Callback=ProgressPercentage(local_edit6))\n",
    "s3_upload.upload_file(local_edit7, s3_bucket, s3_key_edit7,\n",
    "                         Callback=ProgressPercentage(local_edit7))\n",
    "s3_upload.upload_file(local_edit8, s3_bucket, s3_key_edit8,\n",
    "                         Callback=ProgressPercentage(local_edit8))\n",
    "# Merged \n",
    "\n",
    "s3_upload.upload_file(tmp_merge, s3_bucket, s3_key_merge,\n",
    "           Callback=ProgressPercentage(tmp_merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"Zs3_key\"] = \"s3://wri-public-data/\" + s3_key_merge\n",
    "os.environ[\"Zgs_key\"] = \"gs://resource-watch-public/\" + s3_key_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Non-MD5 etag (\"66267f84f56b7e6ab60a2c1d9c7a24ab-4\") present for key <Key: wri-public-data,resourcewatch/raster/foo_027_yield_gaps_for_major_crops/foo_027_yield_gaps_for_major_crops.tif>, data integrity checks are not possible.\n",
      "Copying s3://wri-public-data/resourcewatch/raster/foo_027_yield_gaps_for_major_crops/foo_027_yield_gaps_for_major_crops.tif [Content-Type=binary/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 26.3 MiB]                                                \n",
      "-\n",
      "- [0 files][  5.7 MiB/ 26.3 MiB]                                                \n",
      "\\\n",
      "|\n",
      "| [0 files][ 15.2 MiB/ 26.3 MiB]                                                \n",
      "/\n",
      "/ [0 files][ 22.4 MiB/ 26.3 MiB]                                                \n",
      "-\n",
      "WARNING: Found no hashes to validate object downloaded from s3://wri-public-data/resourcewatch/raster/foo_027_yield_gaps_for_major_crops/foo_027_yield_gaps_for_major_crops.tif and uploaded to gs://resource-watch-public/resourcewatch/raster/foo_027_yield_gaps_for_major_crops/foo_027_yield_gaps_for_major_crops.tif. Integrity cannot be assured without hashes.\n",
      "- [1 files][ 26.3 MiB/ 26.3 MiB]                                                \n",
      "\\\n",
      "\n",
      "Operation completed over 1 objects/26.3 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp %Zs3_key% %Zgs_key%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started upload task with ID: VKK77Z6SPWRCGNLIHEMXIIB2\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"asset_id\"] = \"users/resourcewatch/foo_027_yield_gaps_for_major_crops\"\n",
    "!earthengine upload image --asset_id=%asset_id% %Zgs_key%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"band_names\"] = str(band_ids)\n",
    "!earthengine asset set -p band_names=\"%band_names%\" %asset_id%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
