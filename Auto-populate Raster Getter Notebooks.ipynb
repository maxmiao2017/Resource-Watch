{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert cells programmaticaly to python notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob(\"*.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [fn for fn in glob('*') \n",
    "         if not os.path.basename(fn).endswith('done.ipynb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cli.027.ipynb',\n",
       " 'dis.004.ipynb',\n",
       " 'dis.005.ipynb',\n",
       " 'dis.007.ipynb',\n",
       " 'dis.008.ipynb',\n",
       " 'dis.012.ipynb',\n",
       " 'ene.003.1.ipynb',\n",
       " 'ene.003.2.ipynb',\n",
       " 'ene.004.ipynb',\n",
       " 'ene.006.ipynb',\n",
       " 'ene.015.ipynb',\n",
       " 'ene.018.ipynb',\n",
       " 'foo.005.ipynb',\n",
       " 'foo.017.ipynb',\n",
       " 'foo.023.ipynb',\n",
       " 'foo.028.ipynb',\n",
       " 'soc.031.ipynb',\n",
       " 'soc.032.ipynb',\n",
       " 'wat.015.ipynb',\n",
       " 'wat.029.ipynb']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_overwrite = files[6:]\n",
    "files_to_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standard_fare = [\n",
    "    \n",
    "{'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': [\n",
    "  'Import libraries']},\n",
    "{'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': True},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "\"\"\"# Libraries for downloading data from remote server (may be ftp)\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from contextlib import closing\n",
    "import shutil\n",
    "\n",
    "# Library for uploading/downloading data to/from S3\n",
    "import boto3\n",
    "\n",
    "# Libraries for handling data\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "# from netCDF4 import Dataset\n",
    "# import pandas as pd\n",
    "# import scipy\n",
    "\n",
    "# Libraries for various helper functions\n",
    "# from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "import sys\n",
    "from glob import glob\"\"\"]},\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "{'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': [\n",
    "  's3 tools']},\n",
    "{'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': False},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "  \n",
    "\"\"\"s3_upload = boto3.client(\"s3\")\n",
    "s3_download = boto3.resource(\"s3\")\n",
    "\n",
    "s3_bucket = \"wri-public-data\"\n",
    "s3_folder = \"resourcewatch/raster/*\"\n",
    "\n",
    "s3_file = \"*.tif\"\n",
    "\n",
    "s3_key_orig = s3_folder + s3_file\n",
    "s3_key_edit = s3_key_orig[0:-4] + \"_edit.tif\"\n",
    "\n",
    "\n",
    "class ProgressPercentage(object):\n",
    "        def __init__(self, filename):\n",
    "            self._filename = filename\n",
    "            self._size = float(os.path.getsize(filename))\n",
    "            self._seen_so_far = 0\n",
    "            self._lock = threading.Lock()\n",
    "\n",
    "        def __call__(self, bytes_amount):\n",
    "            # To simplify we'll assume this is hooked up\n",
    "            # to a single filename.\n",
    "            with self._lock:\n",
    "                self._seen_so_far += bytes_amount\n",
    "                percentage = (self._seen_so_far / self._size) * 100\n",
    "                sys.stdout.write(\"\\\\r%s  %s / %s  (%.2f%%)\"%(\n",
    "                        self._filename, self._seen_so_far, self._size,\n",
    "                        percentage))\n",
    "                sys.stdout.flush()\"\"\" ]},\n",
    "   \n",
    "    \n",
    "    \n",
    "{'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': [\n",
    "  'Potentially useful for online directories']},   \n",
    "    \n",
    "    {'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': False},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "\"\"\"# View files in a ftp, see cli.015\n",
    "remote_path = \"ftp://cidportal.jrc.ec.europa.eu/jrc-opendata/EDGAR/datasets/v431_v2\"\n",
    "remote_path_BC = remote_path + \"/BC/TOTALS/\"\n",
    "file = req.urlopen(remote_path_BC).read().splitlines()\n",
    "\n",
    "# Copy from https or ftp\n",
    "with(closing(urlopen(online_folder + most_recent))) as r:\n",
    "    with(open(local_orig, 'wb')) as f:\n",
    "        shutil.copyfileobj(r, f)\"\"\"     \n",
    "  ]},\n",
    "    \n",
    "    \n",
    "{'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': [\n",
    "  'Define local file locations']},             \n",
    "{'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': False},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "\"\"\"local_folder = \"/Users/nathansuberi/Desktop/RW_Data/Rasters/*\"\n",
    "file_name = \"*\"]\n",
    "\n",
    "local_orig = local_folder + file_name\n",
    "\n",
    "orig_extension_length = 4 #4 for each char in .tif\n",
    "local_edit = local_orig[:-orig_extension_length] + \"edit.tif\" \"\"\"     \n",
    "  ]},\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "{'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': ['Use rasterio to reproject and compress']},\n",
    "{'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': False},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "\n",
    "\"\"\"# Note - this is the core of Vizz's netcdf2tif function\n",
    "\n",
    "with rio.open(local_orig, 'r') as src:\n",
    "    # This assumes data is readable by rasterio\n",
    "    # May need to open instead with netcdf4.Dataset, for example\n",
    "   \n",
    "    data = src.read()[0]\n",
    "    \n",
    "    rows = data.shape[0]\n",
    "    columns = data.shape[1]\n",
    "    \n",
    "    print(rows)\n",
    "    print(columns)\n",
    "    \n",
    "    # Latitude bounds\n",
    "    south_lat = -90\n",
    "    north_lat = 90\n",
    "\n",
    "    # Longitude bounds\n",
    "    west_lon = -180\n",
    "    east_lon = 180\n",
    "    \n",
    "    transform = rasterio.transform.from_bounds(west_lon, south_lat, east_lon, north_lat, columns, rows)\n",
    "    \n",
    "    # Profile\n",
    "    \n",
    "    no_data_val = *\n",
    "    target_projection = 'EPSG:4326'\n",
    "    target_data_type = np.float64\n",
    "    \n",
    "    profile = {\n",
    "        'driver':'GTiff', \n",
    "        'height':rows, \n",
    "        'width':columns, \n",
    "        'count':1, \n",
    "        'dtype':target_data_type, \n",
    "        'crs':target_projection, \n",
    "        'transform':transform, \n",
    "        'compress':'lzw', \n",
    "        'nodata': no_data_val\n",
    "    }\n",
    "    \n",
    "    with rio.open(local_edit, \"w\", **profile) as dst:\n",
    "        dst.write(data.astype(profile[\"dtype\"]), 1)\"\"\"\n",
    "  ]},\n",
    "\n",
    "    \n",
    "\n",
    " {'cell_type': 'markdown',\n",
    "  'metadata': {},\n",
    "  'source': ['Upload orig and edit files to s3']},\n",
    " {'cell_type': 'code',\n",
    "  'execution_count': 0,\n",
    "  'metadata': {'collapsed': False},\n",
    "  'outputs': [],\n",
    "  'source': [\n",
    "      \n",
    "\"\"\"# Original\n",
    "s3_upload.upload_file(local_orig, s3_bucket, s3_key_orig,\n",
    "                         Callback=ProgressPercentage(local_orig))\n",
    "\n",
    "# Edit\n",
    "s3_upload.upload_file(local_edit, s3_bucket, s3_key_edit,\n",
    "                         Callback=ProgressPercentage(local_edit))\"\"\"\n",
    "      \n",
    "  ]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_fare = standard_fare\n",
    "for cell in s_fare:\n",
    "    if 'execution_count' in cell.keys():\n",
    "        cell['execution_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cell_type': 'markdown', 'metadata': {}, 'source': ['Import libraries']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': True},\n",
       "  'outputs': [],\n",
       "  'source': ['# Libraries for downloading data from remote server (may be ftp)\\nimport requests\\nfrom urllib.request import urlopen\\nfrom contextlib import closing\\nimport shutil\\n\\n# Library for uploading/downloading data to/from S3\\nimport boto3\\n\\n# Libraries for handling data\\nimport rasterio as rio\\nimport numpy as np\\n# from netCDF4 import Dataset\\n# import pandas as pd\\n# import scipy\\n\\n# Libraries for various helper functions\\n# from datetime import datetime\\nimport os\\nimport threading\\nimport sys\\nfrom glob import glob']},\n",
       " {'cell_type': 'markdown', 'metadata': {}, 'source': ['s3 tools']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': False},\n",
       "  'outputs': [],\n",
       "  'source': ['s3_upload = boto3.client(\"s3\")\\ns3_download = boto3.resource(\"s3\")\\n\\ns3_bucket = \"wri-public-data\"\\ns3_folder = \"resourcewatch/raster/*\"\\n\\ns3_file = \"*.tif\"\\n\\ns3_key_orig = s3_folder + s3_file\\ns3_key_edit = s3_key_orig[0:-4] + \"_edit.tif\"\\n\\n\\nclass ProgressPercentage(object):\\n        def __init__(self, filename):\\n            self._filename = filename\\n            self._size = float(os.path.getsize(filename))\\n            self._seen_so_far = 0\\n            self._lock = threading.Lock()\\n\\n        def __call__(self, bytes_amount):\\n            # To simplify we\\'ll assume this is hooked up\\n            # to a single filename.\\n            with self._lock:\\n                self._seen_so_far += bytes_amount\\n                percentage = (self._seen_so_far / self._size) * 100\\n                sys.stdout.write(\"\\\\r%s  %s / %s  (%.2f%%)\"%(\\n                        self._filename, self._seen_so_far, self._size,\\n                        percentage))\\n                sys.stdout.flush()']},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['Potentially useful for online directories']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': False},\n",
       "  'outputs': [],\n",
       "  'source': ['# View files in a ftp, see cli.015\\nremote_path = \"ftp://cidportal.jrc.ec.europa.eu/jrc-opendata/EDGAR/datasets/v431_v2\"\\nremote_path_BC = remote_path + \"/BC/TOTALS/\"\\nfile = req.urlopen(remote_path_BC).read().splitlines()\\n\\n# Copy from https or ftp\\nwith(closing(urlopen(online_folder + most_recent))) as r:\\n    with(open(local_orig, \\'wb\\')) as f:\\n        shutil.copyfileobj(r, f)']},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['Define local file locations']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': False},\n",
       "  'outputs': [],\n",
       "  'source': ['local_folder = \"/Users/nathansuberi/Desktop/RW_Data/Rasters/*\"\\nfile_name = \"*\"]\\n\\nlocal_orig = local_folder + file_name\\n\\norig_extension_length = 4 #4 for each char in .tif\\nlocal_edit = local_orig[:-orig_extension_length] + \"edit.tif\" ']},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['Use rasterio to reproject and compress']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': False},\n",
       "  'outputs': [],\n",
       "  'source': ['# Note - this is the core of Vizz\\'s netcdf2tif function\\n\\nwith rio.open(local_orig, \\'r\\') as src:\\n   \\n   # This assumes data is readable by rasterio\\n   # May need to open instead with netcdf4.Dataset, for example\\n   \\n    data = src.read()[0]\\n    \\n    rows = data.shape[0]\\n    columns = data.shape[1]\\n    \\n    print(rows)\\n    print(columns)\\n    \\n    # Latitude bounds\\n    south_lat = -90\\n    north_lat = 90\\n\\n    # Longitude bounds\\n    west_lon = -180\\n    east_lon = 180\\n    \\n    transform = rasterio.transform.from_bounds(west_lon, south_lat, east_lon, north_lat, columns, rows)\\n    \\n    # Profile\\n    \\n    no_data_val = *\\n    target_projection = \\'EPSG:4326\\'\\n    target_data_type = np.float64\\n    \\n    profile = {\\n        \\'driver\\':\\'GTiff\\', \\n        \\'height\\':rows, \\n        \\'width\\':columns, \\n        \\'count\\':1, \\n        \\'dtype\\':target_data_type, \\n        \\'crs\\':target_projection, \\n        \\'transform\\':transform, \\n        \\'compress\\':\\'lzw\\', \\n        \\'nodata\\': no_data_val\\n    }\\n    \\n    with rio.open(local_edit, \"w\", **profile) as dst:\\n        dst.write(data.astype(profile[\"dtype\"]), 1)']},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['Upload orig and edit files to s3']},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 0,\n",
       "  'metadata': {'collapsed': False},\n",
       "  'outputs': [],\n",
       "  'source': ['# Original\\ns3_upload.upload_file(local_orig, s3_bucket, s3_key_orig,\\n                         Callback=ProgressPercentage(local_orig))\\n\\n# Edit\\ns3_upload.upload_file(local_edit, s3_bucket, s3_key_edit,\\n                         Callback=ProgressPercentage(local_edit))']}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(files_to_overwrite[3], 'r')\n",
    "j = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j[\"cells\"] = [j[\"cells\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fare in standard_fare:\n",
    "    j[\"cells\"].append(fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.ipynb', 'w') as outfile:\n",
    "    json.dump(j, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cli.027.ipynb',\n",
       " 'dis.004.ipynb',\n",
       " 'dis.005.ipynb',\n",
       " 'dis.007.ipynb',\n",
       " 'dis.008.ipynb',\n",
       " 'dis.012.ipynb',\n",
       " 'ene.003.1.ipynb',\n",
       " 'ene.003.2.ipynb',\n",
       " 'ene.004.ipynb',\n",
       " 'ene.006.ipynb',\n",
       " 'ene.015.ipynb',\n",
       " 'ene.018.ipynb',\n",
       " 'foo.005.ipynb',\n",
       " 'foo.017.ipynb',\n",
       " 'foo.023.ipynb',\n",
       " 'foo.028.ipynb',\n",
       " 'soc.031.ipynb',\n",
       " 'soc.032.ipynb',\n",
       " 'wat.015.ipynb',\n",
       " 'wat.029.ipynb']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli.027.ipynb\n",
      "dis.004.ipynb\n",
      "dis.005.ipynb\n",
      "dis.007.ipynb\n",
      "dis.008.ipynb\n",
      "dis.012.ipynb\n",
      "ene.003.1.ipynb\n",
      "ene.003.2.ipynb\n",
      "ene.004.ipynb\n",
      "ene.006.ipynb\n",
      "ene.015.ipynb\n",
      "ene.018.ipynb\n",
      "foo.005.ipynb\n",
      "foo.017.ipynb\n",
      "foo.023.ipynb\n",
      "foo.028.ipynb\n",
      "soc.031.ipynb\n",
      "soc.032.ipynb\n",
      "wat.015.ipynb\n",
      "wat.029.ipynb\n"
     ]
    }
   ],
   "source": [
    "for file in files_to_overwrite:\n",
    "    print(file)\n",
    "    f = open(file, 'r')\n",
    "    j = json.load(f)\n",
    "    j[\"cells\"] = [j[\"cells\"][0]]\n",
    "    for fare in s_fare:\n",
    "        j[\"cells\"].append(fare)\n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(j, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
